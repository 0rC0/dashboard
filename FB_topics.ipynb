{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyzing Topical Model of Facebook's Topics aiming towards Users. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e28d2810b189>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdivision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprint_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# for word vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWord2Vec\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mw2v\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "# for word vec\n",
    "import gensim\n",
    "from gensim.models import Word2Vec as w2v\n",
    "import gensim.corpora as corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import LdaModel\n",
    "from gensim.corpora import Dictionary\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "import codecs\n",
    "import glob\n",
    "import multiprocessing\n",
    "import os\n",
    "import nltk\n",
    "import pprint\n",
    "import re\n",
    "import sklearn.manifold\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into words\n",
    "def get_words(raw):\n",
    "    \"\"\"\n",
    "    :raw: text that has not been cleaned yet\n",
    "    output: Stemmed Tokens\n",
    "    \"\"\"\n",
    "    from nltk.tokenize import word_tokenize\n",
    "    import string\n",
    "    from nltk.corpus import stopwords\n",
    "    from nltk.stem.porter import PorterStemmer\n",
    "    tokens = word_tokenize(raw)\n",
    "    # convert to lower case\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    # remove punctuation from each word\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    stripped = [w.translate(table) for w in tokens]\n",
    "    # remove remaining tokens that are not alphabetic\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    # filter out stop words\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    porter = PorterStemmer()\n",
    "    stemmed = [porter.stem(word) for word in words]\n",
    "    return stemmed\n",
    "\n",
    "def get_topic_distribution(lda_model, raw_input, dictionary):\n",
    "    \"\"\"Return a vecor of topical distribution of each document or text. \n",
    "    :param lda_model: the output of the function gensim.models.ldamodel.LdaModel\n",
    "    :param raw_imput: raw chinese policy text or doc\n",
    "    :param dictionary: the output of corpora.Dictionary() function which is the vocab.\n",
    "    \"\"\"\n",
    "    from pandas import DataFrame\n",
    "    other_texts = [ # needs tokenized\n",
    "        get_words(raw_input)\n",
    "    ]\n",
    "    #dictionary = Dictionary(sentences)\n",
    "    other_corpus = [dictionary.doc2bow(text) for text in other_texts]\n",
    "    unseen_doc = other_corpus[0]\n",
    "    vector = lda_model[unseen_doc][0]\n",
    "    return(DataFrame.from_records(vector)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Does politcal advertisements have an impact on the US November election? \n",
    "## Testing on random sample of Facebook users:\n",
    "- Only English \n",
    "- From October to December\n",
    "- Testing the US election in November vs FB ads political influence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "df = pd.read_csv('/home/ubuntu/Desktop/dataset_eu19/user_a.csv')\n",
    "random.seed(10)\n",
    "RANDOM_SAMPLE = df.iloc[:, 0:22].sample(10000) # just taking a random sample of the population"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SAMPLE['publicationTime'] = pd.to_datetime(RANDOM_SAMPLE['publicationTime']).dt.date\n",
    "RANDOM_SAMPLE = RANDOM_SAMPLE.sort_values(by='publicationTime')\n",
    "RANDOM_SAMPLE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break into tokens for each sentence\n",
    "import time\n",
    "start = time.time()\n",
    "sent = RANDOM_SAMPLE.concatenatedText\n",
    "\n",
    "sentences = []\n",
    "for i in sent:\n",
    "    sentences.append(get_words(i))\n",
    "end = time.time()\n",
    "print(end-start, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.sklearn\n",
    "import gensim\n",
    "import os\n",
    "import dill\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim  # don't skip this\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec as w2v\n",
    "import time\n",
    "\n",
    "# Create Dictionary\n",
    "start = time.time()\n",
    "id2word = corpora.Dictionary(sentences)\n",
    "dictionary = Dictionary(sentences)\n",
    "# Create Corpus\n",
    "texts = sentences\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True,\n",
    "                                           minimum_probability=0.0)\n",
    "\n",
    "\n",
    "\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, id2word)\n",
    "\n",
    "#pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.show(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge the original dataset with the Topical Distribution spread "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "buckets = []\n",
    "for i in RANDOM_SAMPLE.concatenatedText:\n",
    "    buckets.append(get_topic_distribution(lda_model,i,dictionary))\n",
    "groups= []\n",
    "for i in range(0,len(buckets)):\n",
    "    groups.append(pd.Series.to_frame((buckets[i])).T)\n",
    "\n",
    "groups = pd.concat(groups).reset_index()\n",
    "DATA =  pd.concat([RANDOM_SAMPLE.reset_index(drop=True), groups],axis=1).reset_index(drop=True)\n",
    "end = time.time()\n",
    "print(end-start)\n",
    "import dill\n",
    "dill.dump_session('FBenv.db')\n",
    "#dill.load_session('FBenv.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.columns = [           'ANGRY',             'HAHA',             'LIKE',\n",
    "                   'LOVE',              'SAD',              'WOW',\n",
    "          'displaySource',       'fblinktype',               'id',\n",
    "           'images.count',  'impressionOrder',   'impressionTime',\n",
    "                 'nature',        'permaLink',           'postId',\n",
    "        'publicationTime',           'source',       'sourceLink',\n",
    "               'timeline',             'user', 'concatenatedText',\n",
    "         'concatLanguage',            'index',                  'Politics',\n",
    "                        'Advertisement',                  'Other']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ORGANIC = DATA[DATA.nature == 'organic']\n",
    "SPONSOR = DATA[DATA.nature == 'sponsored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.plotly as py\n",
    "import plotly.graph_objs as go\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "init_notebook_mode(connected=True)\n",
    "import pandas as pd\n",
    "import math\n",
    "import math\n",
    "from bubbly.bubbly import add_slider_steps\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "\n",
    "#ORGANIC['publicationTime']=pd.to_datetime(ORGANIC['publicationTime']).dt.date\n",
    "EX = pd.DataFrame(ORGANIC.groupby('publicationTime')[['Politics','Advertisement','Other']].mean()).reset_index(inplace=False)\n",
    "\n",
    "x= EX.publicationTime\n",
    "\n",
    "trace1 = dict(\n",
    "    x= x,\n",
    "    y= EX['Advertisement'],\n",
    "    name='Advertisement',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(131, 90, 241)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace2 = dict(\n",
    "    x= x,\n",
    "    y= EX['Politics'],\n",
    "    name='Politics',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(111, 231, 219)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace3 = dict(\n",
    "    x= x,\n",
    "    y= EX['Other'],\n",
    "    name='Other',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(184, 247, 212)'),\n",
    "    stackgroup='one')\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(\n",
    "    \n",
    "    legend=dict(x=0, y=-.13,\n",
    "       orientation=\"h\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topical Distribution Spread from Organic Posts Before and After the Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "EX = pd.DataFrame(SPONSOR.groupby('publicationTime')[['Politics','Advertisement','Other']].mean()).reset_index(inplace=False)\n",
    "\n",
    "x= EX.publicationTime\n",
    "\n",
    "trace1 = dict(\n",
    "    x= x,\n",
    "    y= EX['Advertisement'],\n",
    "    name='Sales Ad',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(131, 90, 241)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace2 = dict(\n",
    "    x= x,\n",
    "    y= EX['Politics'],\n",
    "    name='Political Ad',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(111, 231, 219)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace3 = dict(\n",
    "    x= x,\n",
    "    y= EX['Other'],\n",
    "    name='Other Ad',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(184, 247, 212)'),\n",
    "    stackgroup='one')\n",
    "\n",
    "\n",
    "data = [trace1, trace2, trace3]\n",
    "\n",
    "layout = go.Layout(\n",
    "    \n",
    "    legend=dict(x=0, y=-.13,\n",
    "       orientation=\"h\")\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sponsored Posts Topical Spread Before and After the Election"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data, layout=layout)\n",
    "iplot(fig) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How much does each User's gets exposed to these Political Advertisements? \n",
    "- Study case: pick user with ID \"churros-collards-crisp\" because he or she has the most impressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-f6d2db297a0d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# We will now ananlyze the User's exposure to these Politcal, Advertisements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.user.value_counts() # We will now ananlyze the User's exposure to these Politcal, Advertisements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = df[df['user']=='churros-collards-crisp']\n",
    "USER['publicationTime'] = pd.to_datetime(USER['publicationTime']).dt.date\n",
    "USER = USER.sort_values(by='publicationTime')\n",
    "\n",
    "sent = USER.concatenatedText\n",
    "sentences = []\n",
    "for i in sent:\n",
    "    sentences.append(get_words(i))\n",
    "\n",
    "id2word = corpora.Dictionary(sentences)\n",
    "dictionary = Dictionary(sentences)\n",
    "# Create Corpus\n",
    "texts = sentences\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=3, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True,\n",
    "                                           minimum_probability=0.0)\n",
    "lda_model.print_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "buckets = []\n",
    "for i in USER.concatenatedText:\n",
    "    buckets.append(get_topic_distribution(lda_model,i,dictionary))\n",
    "groups= []\n",
    "for i in range(0,len(buckets)):\n",
    "    groups.append(pd.Series.to_frame((buckets[i])).T)\n",
    "\n",
    "groups = pd.concat(groups).reset_index()\n",
    "USER_DATA =  pd.concat([USER.reset_index(drop=True), groups],axis=1).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "USER_DATA.columns = [           'ANGRY',             'HAHA',             'LIKE',\n",
    "                   'LOVE',              'SAD',              'WOW',\n",
    "          'displaySource',       'fblinktype',               'id',\n",
    "           'images.count',  'impressionOrder',   'impressionTime',\n",
    "                 'nature',        'permaLink',           'postId',\n",
    "        'publicationTime',           'source',       'sourceLink',\n",
    "               'timeline',             'user', 'concatenatedText',\n",
    "         'concatLanguage',             'time',          'topic_0',\n",
    "                'topic_1',          'topic_2',          'topic_3',\n",
    "                'topic_4',          'topic_5',          'topic_6',\n",
    "                'topic_7',          'topic_8',          'topic_9',\n",
    "               'topic_10',         'topic_11',         'topic_12',\n",
    "               'topic_13',         'topic_14',         'topic_15',\n",
    "               'topic_16',         'topic_17',         'topic_18',\n",
    "               'topic_19',         'topic_20',         'topic_21',\n",
    "               'topic_22',         'topic_23',         'topic_24',\n",
    "               'topic_25',         'topic_26',         'topic_27',\n",
    "               'topic_28',         'topic_29',         'topic_30',\n",
    "               'topic_31',         'topic_32',         'topic_33',\n",
    "               'topic_34',         'topic_35',         'topic_36',\n",
    "               'topic_37',         'topic_38',         'topic_39',\n",
    "               'topic_40',         'topic_41',         'topic_42',\n",
    "               'topic_43',         'topic_44',         'topic_45',\n",
    "               'topic_46',         'topic_47',         'topic_48',\n",
    "               'topic_49',            'index',                  'Advertisement',\n",
    "                        'Other',                  'Politics']\n",
    "USER_ORGANIC = USER_DATA[USER_DATA.nature == 'organic']\n",
    "USER_SPONSOR = USER_DATA[USER_DATA.nature == 'sponsored']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bubbly.bubbly import add_slider_steps\n",
    "import plotly.offline as py\n",
    "import plotly.graph_objs as go\n",
    "py.init_notebook_mode(connected=True)\n",
    "from plotly import tools\n",
    "import plotly.figure_factory as ff \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "import plotly.plotly as py\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "\n",
    "\n",
    "EX = pd.DataFrame(USER_ORGANIC.groupby('publicationTime')[['Politics','Advertisement','Other']].mean()).reset_index(inplace=False)\n",
    "\n",
    "x= EX.publicationTime\n",
    "\n",
    "trace1 = dict(\n",
    "    x= x,\n",
    "    y= EX['Advertisement'],\n",
    "    name='Organic Forwarded Ads',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(131, 90, 241)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace2 = dict(\n",
    "    x= x,\n",
    "    y= EX['Politics'],\n",
    "    name='Organic Political Posts',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(111, 231, 219)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace3 = dict(\n",
    "    x= x,\n",
    "    y= EX['Other'],\n",
    "    name='Other Organic Posts',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(184, 247, 212)'),\n",
    "    stackgroup='one')\n",
    "\n",
    "trace_median0 =  go.Scatter(x=['2018-11-07', '2018-11-07'],\n",
    "                            y=[0,1],\n",
    "                            mode=\"lines\",\n",
    "                            legendgroup=\"a\",\n",
    "                            showlegend=True,\n",
    "                            marker=dict(size=20,\n",
    "                                       line=dict(width=1),\n",
    "                                       color=\"black\"\n",
    "                                       ),\n",
    "                            name=\"US Mid-term Election 2018\",\n",
    "                            visible=True\n",
    "                            )\n",
    "\n",
    "data_organic = [trace1, trace2, trace3, trace_median0]\n",
    "\n",
    "layout = go.Layout(\n",
    "\n",
    "    legend=dict(x=0, y=-.13,\n",
    "       orientation=\"h\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EX = pd.DataFrame(USER_SPONSOR.groupby('publicationTime')[['Politics','Advertisement','Other']].mean()).reset_index(inplace=False)\n",
    "\n",
    "x= EX.publicationTime\n",
    "\n",
    "trace1 = dict(\n",
    "    x= x,\n",
    "    y= EX['Advertisement'],\n",
    "    name='Sponsored Advertisement',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(131, 90, 241)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace2 = dict(\n",
    "    x= x,\n",
    "    y= EX['Politics'],\n",
    "    name='Sponsored Politics',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(111, 231, 219)'),\n",
    "    stackgroup='one'\n",
    ")\n",
    "trace3 = dict(\n",
    "    x= x,\n",
    "    y= EX['Other'],\n",
    "    name='Other Sponsors',\n",
    "    hoverinfo='x+y',\n",
    "    mode='lines',\n",
    "    line=dict(width=0.5),\n",
    "              #color='rgb(184, 247, 212)'),\n",
    "    stackgroup='one')\n",
    "\n",
    "trace_median1 =  go.Scatter(x=['2018-11-07', '2018-11-07'],\n",
    "                            #y=[0,1],\n",
    "                            mode=\"lines\",\n",
    "                            legendgroup=\"a\",\n",
    "                            showlegend=True,\n",
    "                            marker=dict(size=20,\n",
    "                                       line=dict(width=1),\n",
    "                                       color=\"black\"\n",
    "                                       ),\n",
    "                            name=\"US Mid-term Election 2018\",\n",
    "                            visible=True\n",
    "                            )\n",
    "\n",
    "data_sponsored = [trace1, trace2, trace3, trace_median1]\n",
    "\n",
    "layout = go.Layout(\n",
    "    yaxis=dict( autorange=True,\n",
    "               fixedrange = False),\n",
    "    legend=dict(x=0, y=-.13,\n",
    "       orientation=\"h\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How does Facebook impact A user's timeline impression during Political Elections?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For USER ***churros-collards-crisp*** Personal timeline impression exposure (below)\n",
    "> ## Organic Posts: political posts are about 10% higher in proportion before the midterm election on November 7th. \n",
    "> * We can conclude that he is more likely to be influenced by his own political social network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data_organic, layout=layout)\n",
    "iplot(fig) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ## Sponsored Posts for User **churros-collards-crisp**: \n",
    "> * Growth of 2% to 19% just 3 days before the US midterm election. \n",
    "> * He may be heavily influenced by Sponsored Political ads 2 weeks before the election."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=data_sponsored, layout=layout)\n",
    "iplot(fig) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
